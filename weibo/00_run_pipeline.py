#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¾®åšæ•°æ®BERTopicä¸»é¢˜å»ºæ¨¡å®Œæ•´æµç¨‹è¿è¡Œè„šæœ¬
æŒ‰é¡ºåºæ‰§è¡Œï¼šæ•°æ®é¢„å¤„ç† -> è¯æ±‡åˆ†æ -> åˆ†è¯ -> åµŒå…¥å‘é‡ç”Ÿæˆ -> ä¸»é¢˜å»ºæ¨¡ -> è¯„ä¼°åˆ†æ
"""

import os
import sys
import subprocess
import time
import shutil

def run_step(step_name, script_path, description, timeout=None):
    """è¿è¡Œå•ä¸ªå¤„ç†æ­¥éª¤"""
    print(f"\n{'='*60}")
    print(f"æ­¥éª¤: {step_name}")
    print(f"æè¿°: {description}")
    print(f"è„šæœ¬: {script_path}")
    print(f"{'='*60}")
    
    start_time = time.time()
    
    try:
        # è¿è¡Œè„šæœ¬
        cmd = [sys.executable, script_path]
        result = subprocess.run(cmd, 
                              capture_output=True, 
                              text=True, 
                              encoding='utf-8',
                              timeout=timeout)
        
        # æ‰“å°è¾“å‡º
        if result.stdout:
            print("è¾“å‡º:")
            print(result.stdout)
        
        if result.stderr:
            print("é”™è¯¯:")
            print(result.stderr)
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
        if result.returncode == 0:
            elapsed_time = time.time() - start_time
            print(f"âœ… {step_name} å®Œæˆ (è€—æ—¶: {elapsed_time:.2f}ç§’)")
            return True
        else:
            print(f"âŒ {step_name} å¤±è´¥ (è¿”å›ç : {result.returncode})")
            return False
            
    except subprocess.TimeoutExpired:
        print(f"âŒ {step_name} è¶…æ—¶")
        return False
    except Exception as e:
        print(f"âŒ {step_name} æ‰§è¡Œå¼‚å¸¸: {e}")
        return False

def check_file_exists(file_path, description):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    if os.path.exists(file_path):
        file_size = os.path.getsize(file_path)
        size_str = f"({file_size:,} bytes)" if file_size < 1024*1024 else f"({file_size/1024/1024:.1f} MB)"
        print(f"âœ… {description}: {file_path} {size_str}")
        return True
    else:
        print(f"âŒ {description}: {file_path} (æ–‡ä»¶ä¸å­˜åœ¨)")
        return False

def create_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    directories = [
        "data",
        "results", 
        "vocabulary_analysis",
        "embedding",
        "åˆ†è¯"
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"ğŸ“ ç¡®ä¿ç›®å½•å­˜åœ¨: {directory}")

def backup_userdict():
    """å¤‡ä»½ç”¨æˆ·è‡ªå®šä¹‰è¯å…¸"""
    original_file = "åˆ†è¯/userdict.txt"
    backup_file = "åˆ†è¯/userdict_backup.txt"
    
    if os.path.exists(original_file):
        shutil.copy2(original_file, backup_file)
        print(f"ğŸ“‹ å¤‡ä»½ç”¨æˆ·è¯å…¸: {backup_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("=== å¾®åšæ•°æ®BERTopicä¸»é¢˜å»ºæ¨¡å®Œæ•´æµç¨‹ ===")
    print("å¼€å§‹æ—¶é—´:", time.strftime("%Y-%m-%d %H:%M:%S"))
    
    # åˆ›å»ºå¿…è¦ç›®å½•
    print("\nåˆ›å»ºå¿…è¦ç›®å½•...")
    create_directories()
    
    # å¤‡ä»½ç”¨æˆ·è¯å…¸
    backup_userdict()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    print("\næ£€æŸ¥è¾“å…¥æ–‡ä»¶...")
    input_file = "data/data_new.xlsx"
    if not check_file_exists(input_file, "è¾“å…¥Excelæ–‡ä»¶"):
        print("è¯·ç¡®ä¿data_new.xlsxæ–‡ä»¶å­˜åœ¨äºdataç›®å½•ä¸­")
        return
    
    # æ­¥éª¤1: æ•°æ®é¢„å¤„ç†
    step1_success = run_step(
        "æ•°æ®é¢„å¤„ç†",
        "1_data_preprocessing.py",
        "æ¸…ç†Excelæ•°æ®ï¼Œæå–æ–‡æœ¬å’Œæ—¶é—´ä¿¡æ¯"
    )
    
    if not step1_success:
        print("æ•°æ®é¢„å¤„ç†å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
        return
    
    # æ£€æŸ¥é¢„å¤„ç†ç»“æœ
    print("\næ£€æŸ¥é¢„å¤„ç†ç»“æœ...")
    check_file_exists("data/æ–‡æœ¬.txt", "æ¸…ç†åçš„æ–‡æœ¬æ–‡ä»¶")
    check_file_exists("data/æ—¶é—´.txt", "æ—¶é—´ä¿¡æ¯æ–‡ä»¶")
    check_file_exists("data/weibo_clean_data.csv", "å®Œæ•´æ¸…ç†æ•°æ®")
    
    # æ­¥éª¤2: è¯æ±‡åˆ†æï¼ˆæ–°å¢ï¼‰
    step2_success = run_step(
        "è¯æ±‡åˆ†æ",
        "2_analyze_vocabulary.py",
        "åˆ†æé«˜é¢‘è¯æ±‡ï¼Œç”Ÿæˆç”¨æˆ·è‡ªå®šä¹‰è¯å…¸å»ºè®®"
    )
    
    if not step2_success:
        print("è¯æ±‡åˆ†æå¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œåç»­æ­¥éª¤")
    else:
        # æ£€æŸ¥è¯æ±‡åˆ†æç»“æœ
        print("\næ£€æŸ¥è¯æ±‡åˆ†æç»“æœ...")
        check_file_exists("vocabulary_analysis/wordcloud.png", "è¯æ±‡äº‘å›¾")
        check_file_exists("åˆ†è¯/userdict_updated.txt", "æ›´æ–°åçš„ç”¨æˆ·è¯å…¸")
    
    # æ­¥éª¤3: åˆ†è¯å¤„ç†
    step3_success = run_step(
        "åˆ†è¯å¤„ç†",
        "3_word_segmentation.py",
        "å¯¹æ–‡æœ¬è¿›è¡Œä¸­æ–‡åˆ†è¯"
    )
    
    if not step3_success:
        print("åˆ†è¯å¤„ç†å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
        return
    
    # æ£€æŸ¥åˆ†è¯ç»“æœ
    print("\næ£€æŸ¥åˆ†è¯ç»“æœ...")
    check_file_exists("data/åˆ‡è¯.txt", "åˆ†è¯ç»“æœæ–‡ä»¶")
    check_file_exists("data/åˆ‡è¯_word_freq.csv", "è¯é¢‘ç»Ÿè®¡æ–‡ä»¶")
    
    # æ­¥éª¤4: åµŒå…¥å‘é‡ç”Ÿæˆ
    print("\næ³¨æ„: åµŒå…¥å‘é‡ç”Ÿæˆå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
    step4_success = run_step(
        "åµŒå…¥å‘é‡ç”Ÿæˆ",
        "4_generate_embeddings.py",
        "ç”Ÿæˆæ–‡æœ¬åµŒå…¥å‘é‡",
        timeout=3600  # 1å°æ—¶è¶…æ—¶
    )
    
    if not step4_success:
        print("åµŒå…¥å‘é‡ç”Ÿæˆå¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
        return
    
    # æ£€æŸ¥åµŒå…¥å‘é‡ç»“æœ
    print("\næ£€æŸ¥åµŒå…¥å‘é‡ç»“æœ...")
    check_file_exists("data/embedding_sen.npy", "Sentence-TransformersåµŒå…¥å‘é‡")
    check_file_exists("data/embedding_bert.npy", "BERTåµŒå…¥å‘é‡")
    check_file_exists("data/embedding_info.csv", "åµŒå…¥å‘é‡ä¿¡æ¯")
    
    # æ­¥éª¤5: ä¸»é¢˜å»ºæ¨¡
    step5_success = run_step(
        "ä¸»é¢˜å»ºæ¨¡",
        "5_main_weibo.py",
        "ä½¿ç”¨BERTopicè¿›è¡Œä¸»é¢˜å»ºæ¨¡",
        timeout=1800  # 30åˆ†é’Ÿè¶…æ—¶
    )
    
    if not step5_success:
        print("ä¸»é¢˜å»ºæ¨¡å¤±è´¥")
        return
    
    # æ­¥éª¤6: è¯„ä¼°åˆ†æï¼ˆæ–°å¢ï¼‰
    step6_success = run_step(
        "è¯„ä¼°åˆ†æ",
        "6_evaluation_metrics.py",
        "è®¡ç®—ä¸»é¢˜å»ºæ¨¡è¯„ä¼°æŒ‡æ ‡"
    )
    
    if not step6_success:
        print("è¯„ä¼°åˆ†æå¤±è´¥ï¼Œä½†æµç¨‹å·²å®Œæˆ")
    
    # æ£€æŸ¥æœ€ç»ˆç»“æœ
    print("\næ£€æŸ¥æœ€ç»ˆç»“æœ...")
    check_file_exists("results/weibo_clustering_results.csv", "åŸºç¡€èšç±»ç»“æœ")
    check_file_exists("results/weibo_complete_results.csv", "å®Œæ•´èšç±»ç»“æœ")
    check_file_exists("results/weibo_topic_info.csv", "ä¸»é¢˜ä¿¡æ¯")
    check_file_exists("results/weibo_analysis_stats.csv", "åˆ†æç»Ÿè®¡")
    check_file_exists("results/weibo_evaluation_metrics.csv", "è¯„ä¼°æŒ‡æ ‡")
    
    # å®Œæˆ
    print(f"\n{'='*60}")
    print("ğŸ‰ æ‰€æœ‰æ­¥éª¤æ‰§è¡Œå®Œæˆï¼")
    print("ç»“æŸæ—¶é—´:", time.strftime("%Y-%m-%d %H:%M:%S"))
    print(f"{'='*60}")
    
    print("\nğŸ“ ç»“æœæ–‡ä»¶ä½ç½®:")
    print("- æ•°æ®æ–‡ä»¶: data/")
    print("- èšç±»ç»“æœ: results/")
    print("- è¯æ±‡åˆ†æ: vocabulary_analysis/")
    print("- åµŒå…¥å‘é‡: embedding/")
    
    print("\nğŸ“Š ä¸»è¦è¾“å‡ºæ–‡ä»¶:")
    print("- results/weibo_complete_results.csv: å®Œæ•´çš„èšç±»ç»“æœï¼ˆåŒ…å«åŸæ–‡å’Œæ—¶é—´ï¼‰")
    print("- results/weibo_topic_info.csv: ä¸»é¢˜è¯¦ç»†ä¿¡æ¯")
    print("- results/weibo_analysis_stats.csv: åˆ†æç»Ÿè®¡ä¿¡æ¯")
    print("- results/weibo_evaluation_metrics.csv: è¯„ä¼°æŒ‡æ ‡")
    print("- vocabulary_analysis/wordcloud.png: è¯æ±‡äº‘å›¾")
    print("- åˆ†è¯/userdict_updated.txt: æ›´æ–°åçš„ç”¨æˆ·è¯å…¸")
    
    print("\nğŸ’¡ å»ºè®®:")
    print("- æŸ¥çœ‹è¯æ±‡åˆ†æç»“æœï¼Œæ ¹æ®éœ€è¦è°ƒæ•´ç”¨æˆ·è¯å…¸")
    print("- æ£€æŸ¥ä¸»é¢˜è´¨é‡ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´BERTopicå‚æ•°")
    print("- åˆ†æè¯„ä¼°æŒ‡æ ‡ï¼Œä¼˜åŒ–æ¨¡å‹æ€§èƒ½")

if __name__ == "__main__":
    main() 